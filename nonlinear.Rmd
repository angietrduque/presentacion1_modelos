---
title: "*Asociaciones no lineales en el modelo Normal*"
author:  "Angie Rodríguez Duque & César Saavedra Vanegas"
date: "Octubre 30 de 2020"
output:
  ioslides_presentation:
    widescreen: true 
    smaller: true 
    transition: slower
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```


```{r warning=FALSE, include=F, paged.print=TRUE}
suppressMessages(library(deSolve))
suppressMessages(library(nlme))
suppressMessages(library(ggplot2))
suppressMessages(library(plotly))
suppressMessages(library(reshape2))

```


# Introducción
##


# Test de correlación de pearson
##
<div style="text-align: justify">

Se utiliza para estudiar la asociación entre un factor de estudio y una variable de respuesta cuantitativa, mide el grado de asociación entre dos variables tomando valores entre $-1$ y $1$.

+ Valores próximos a $1$ indicarán fuerte asociación lineal positiva.

+ Valores próxi­mos a $-1$ indicarán fuerte asociación lineal negativa.

+ Valores próximos a $0$ indicarán no asociación lineal, lo que no significa que no pueda existir otro tipo de asociación.

<div/>


# Definición
##
<div style="text-align: justify">

Hasta ahora solo hemos considerado asociaciones lineales entre X e y, donde un aumento de delta en una variable explicativa continua xi produce el mismo cambio βi en y para todos los valores de xi. βi a veces se denomina **"Slope"** porque es un gradiente lineal. Una ecuación de regresión lineal simple con una sola pendiente lineal es:

$$E(Y_{i})=\beta_{0}+\beta_{1}x_{i}; \hspace{2cm} i=1,...,N. $$
Una asociación en forma de U se puede modelar agregando una versión cuadrática de la variable y un parámetro $\beta$ adicional:

$$E(Y_{i})=\beta_{0}+\beta_{1}x_{i}+\beta_{2}x^{2}_{i}; \hspace{2cm} i=1,...,N. $$

<div/>

# Centrar
##
<div style="text-align: justify">

En la práctica, cuando se utilizan transformaciones como la cuadrática, que pueden crear valores grandes de xi, puede resultar útil centrar las variables explicativas utilizando su media (x) y escalarlas utilizando su desviación estándar (de). Para mayor comodidad de notación, primero creamos una versión centrada y escalada de $x_i$:

$$\tilde{x}_{i}=\displaystyle{\frac{(x_{i}-\bar{x}_{i})}{sd}}$$
**Tabla:** Estimaciones para el modelo utilizando variables explicativas centradas y escaladas.
<table>
|          Término         	| Estimación $b_{j}$ 	| Error estándar 	|
| ------------------------	|  ------------------	|  --------------	|
| Constante                	|             37.600 	|          1.332 	|
| Coeficiente para la edad 	|             -1.452 	|          1.397 	|
| Coeficiente de peso      	|             -3.793 	|          1.385 	|
| Coeficiente de proteína  	|             4.350  	|          1.411 	|


<div/>

# Ajuste del modelo
##
<div style="text-align: justify">

Y se ajusta al modelo:

$$E(Y_{i})=\beta_{0}+\beta_{1}\tilde{x}_{i}+\beta_{2}\tilde{x}^{2}_{i}$$
<div/>

# Ventajas
##
<div style="text-align: justify">

* Una ventaja adicional del centrado es que la estimación de la intersección $\beta_{0}$ ahora relaciona el valor de y promedio con el valor de $x$ promedio en lugar del valor de $y$ promedio cuando $x$ es cero, lo que puede no ser significativo si $x$ no puede ser cero. **Ejemplo:** El peso de una persona.

* Además, los parámetros de **"Slope"** ahora representan un cambio de una desviación estándar que es potencialmente más significativo que un cambio de una sola unidad que puede ser muy pequeño o grande.

* Por último, escalar por la desviación estándar facilita la comparación de la importancia de las variables.

<div/>

# Ejemplo en R
##
<div style="text-align: justify">

### Regresión polinomial

Una marca de coches quiere generar un modelo de regresión que permita predecir el consumo de combustible *(mpg)* en función de la potencia del motor *(horsepower)*.

```{r warning=FALSE, include=T, paged.print=F}
library(ISLR)
attach(Auto)
plot(x = horsepower, y = mpg, main = "Consumo vs potencia motor", pch = 20,
     col = "grey")
```

<div>


# Bibliografía
##

* Dobson, A. J., & Barnett, A. G. (2018). An introduction to generalized linear models. CRC press.

